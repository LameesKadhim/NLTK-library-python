{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nltk library python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvCSgdHtU5Lkxa6mgbSXGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LameesKadhim/NLTK-library-python/blob/main/nltk_library_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McF3FeyZlaMu"
      },
      "source": [
        "## **NLTK is a popular python library which is used for natural language processing NLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEfw83rmOqb"
      },
      "source": [
        "### **seperating a text to a group of sentences or words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMmfEy8T1u8-",
        "outputId": "6f96a494-8153-4df7-c26d-63793654e5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb14WG031kjf"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmVsHpAwcZh-",
        "outputId": "1822db76-80c6-48ef-ef83-d1671eb46128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "\n",
        "\n",
        "#seperate the sentences using the dots between them\n",
        "nltk.download('punkt')\n",
        "\n",
        "#seperate by sentence\n",
        "from nltk import sent_tokenize\n",
        "mytext = 'Hello Mr. Adam, how are you? I hope everything is going well. Today is a good day, see you.'\n",
        "print('\\nsent_tokenize: ', sent_tokenize(mytext))\n",
        "\n",
        "#seperate by words\n",
        "from nltk.tokenize import word_tokenize\n",
        "mytext = 'Hello Mr. Adam, how are you? I hope everything is going well. Today is a good day, see you.'\n",
        "print('\\nword_tokenize', word_tokenize(mytext))\n",
        "\n",
        "#using language other than english\n",
        "mytext = 'Hallo Herr Adam, wie geht es Ihnen? Ich hoffe alles läuft gut. Heute ist ein guter Tag, wir sehen uns.'\n",
        "print('\\nsent_tokenize', sent_tokenize(mytext,'german'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "\n",
            "sent_tokenize:  ['Hello Mr. Adam, how are you?', 'I hope everything is going well.', 'Today is a good day, see you.']\n",
            "\n",
            "word_tokenize ['Hello', 'Mr.', 'Adam', ',', 'how', 'are', 'you', '?', 'I', 'hope', 'everything', 'is', 'going', 'well', '.', 'Today', 'is', 'a', 'good', 'day', ',', 'see', 'you', '.']\n",
            "\n",
            "sent_tokenize ['Hallo Herr Adam, wie geht es Ihnen?', 'Ich hoffe alles läuft gut.', 'Heute ist ein guter Tag, wir sehen uns.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbDmq3sHpcg2"
      },
      "source": [
        "### **Definition, antonyms, synonymous & stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evIgR8cwsYz5",
        "outputId": "95a07528-c6ae-4a3e-fc6f-90be5918f89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR_qgYkwGrXa",
        "outputId": "bc21ff65-c6af-45be-d3ba-3adecee887d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#get definition of word\n",
        "syn  = wordnet.synsets('pain')\n",
        "print('pain is', syn[2].definition())\n",
        "print('an example is ', syn[2].examples())\n",
        "print('--------------------------------------------')\n",
        "\n",
        "syn  = wordnet.synsets('NLP')\n",
        "print('NLP is', syn[0].definition())\n",
        "print('--------------------------------------------')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pain is a somatic sensation of acute discomfort\n",
            "an example is  ['as the intensity increased the sensation changed from tickle to pain']\n",
            "--------------------------------------------\n",
            "NLP is the branch of information science that deals with natural language information\n",
            "--------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmIF6xn1Gu8x",
        "outputId": "a68d2ec1-9c51-455b-cdfc-85b8ef3c2a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# To get the list of synonyms:\n",
        "synonyms = []\n",
        "for syn in wordnet.synsets('Computer'):\n",
        "  for lemma in syn.lemmas():\n",
        "    synonyms.append(lemma.name())\n",
        "print('synonyms of computer is', synonyms)\n",
        "print('--------------------------------------------')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "synonyms of computer is ['computer', 'computing_machine', 'computing_device', 'data_processor', 'electronic_computer', 'information_processing_system', 'calculator', 'reckoner', 'figurer', 'estimator', 'computer']\n",
            "--------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IGpnu1OGyCm",
        "outputId": "0f02fd1a-07cf-4b74-b664-e93fce4dc46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# TO get antonyms  of word\n",
        "Opposite = []\n",
        "for syn in wordnet.synsets(\"small\"):\n",
        "  for l in syn.lemmas():\n",
        "    if l.antonyms():\n",
        "      Opposite.append(l.antonyms()[0].name())\n",
        "print('antonyms of small is', Opposite)\n",
        "print('-------------------------------------------')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "antonyms of small is ['large', 'big', 'big']\n",
            "-------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd-WySPR2BbH",
        "outputId": "06ffb9d7-9438-4520-a53a-bcc3ea25befe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# word stemming which means removing affexes of word and returning the root word\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "print('word stemming for computation is', stemmer.stem('computation'))\n",
        "print('-------------------------------------------')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word stemming for computation is comput\n",
            "-------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PSv07u0JhjR"
      },
      "source": [
        "### **stemming words in other languages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCgJYoUwJnbY",
        "outputId": "8eaac3b5-70e7-42ae-da2f-9432d566e870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "print(SnowballStemmer.languages)\n",
        "german_stemmer = SnowballStemmer('german')\n",
        "print('\\nword stemming for trinken', german_stemmer.stem('trinken'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n",
            "\n",
            "word stemming for trinken trink\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TiM2sHoG3_e",
        "outputId": "991d354d-2ba2-4681-8b97-26b16fd16d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# word lemmatizing which is similar to stemming but returns a real word \n",
        "#the result could be verb, noun, adjective and adverb\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print('verb of living is',lemmatizer.lemmatize('living', pos='v')) #verb \n",
        "print('noun of believes is ',lemmatizer.lemmatize('believes', pos='n')) #noun\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "verb of living is live\n",
            "noun of believes is  belief\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO6F6faoGTBs"
      },
      "source": [
        "### **removing stop words from a text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Geau4aZAZPR",
        "outputId": "bb5fb592-9863-494c-a1e5-f91ad4e194a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# removing stop words\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import  word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "data = 'a text is the main body of a book or other piece of writing, as distinct from other material such as notes, appendices, and illustrations.'\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = word_tokenize(data)\n",
        "filtered_words = []\n",
        "\n",
        "for w in words:\n",
        "  if w not in stop_words:\n",
        "    filtered_words.append(w)\n",
        "print('important words are: ',filtered_words)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "important words are:  ['text', 'main', 'body', 'book', 'piece', 'writing', ',', 'distinct', 'material', 'notes', ',', 'appendices', ',', 'illustrations', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEy9ScMkIaJ4"
      },
      "source": [
        "### ***POS Tagging***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_GkQMmCKca3",
        "outputId": "15872bc8-6284-41cf-b4a4-5e315cfed50f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "text = word_tokenize('Today is a nice, sunny day')\n",
        "print(pos_tag(text))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('nice', 'JJ'), (',', ','), ('sunny', 'JJ'), ('day', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ5Lh3PHb-b7"
      },
      "source": [
        "### **classifier to distigush between male and female names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5IiGCB2b-vJ",
        "outputId": "439f53b4-a9da-4b4b-cf20-8dd711fa8900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('names')\n",
        "\n",
        "import nltk.classify.util\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import names\n",
        "\n",
        "def gender_feature(word):\n",
        "  return {'last_letter' : word[-1]}\n",
        "\n",
        "#load data and training\n",
        "Names = ([(name, 'male') for name in names.words('male.txt')] +\n",
        "         [(name, 'female') for name in names.words('female.txt')])\n",
        "\n",
        "features_sets = [(gender_feature(Name), Gen) for (Name, Gen) in Names]\n",
        "train_set = features_sets\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "#predict\n",
        "print('Lora is ' , classifier.classify(gender_feature('Lora')))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n",
            "Lora is  female\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}